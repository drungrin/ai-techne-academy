# Revis√£o T√©cnica de Arquitetura - AI Techne Academy

**Data**: 2024-12-11  
**Revisor**: Kilo (Architect Mode)  
**Status do Projeto**: 85% completo  
**Vers√£o**: 1.0.0

---

## üìã Sum√°rio Executivo

### Status Geral: ‚úÖ ARQUITETURA S√ìLIDA

O projeto AI Techne Academy apresenta uma arquitetura bem fundamentada com implementa√ß√£o de alta qualidade. A solu√ß√£o utiliza AWS Step Functions para orquestra√ß√£o, 3 Lambda Functions para coordena√ß√£o, e ECS Fargate para processamento pesado com LLM.

**Pontos Fortes Identificados**: 7  
**Oportunidades de Melhoria**: 12  
**Riscos Cr√≠ticos**: 2  
**Recomenda√ß√µes Priorit√°rias**: 8

---

## üèóÔ∏è 1. AN√ÅLISE DE INTEGRA√á√ÉO DE COMPONENTES

### 1.1 Fluxo de Dados

```mermaid
graph TB
    A[S3 Upload] --> B[EventBridge]
    B --> C[Step Functions]
    C --> D[Lambda: Trigger]
    C --> E[Lambda: Transcribe Starter]
    E --> F[AWS Transcribe]
    F --> G[S3 Transcription]
    C --> H[ECS Fargate Task]
    H --> I[Bedrock Claude 4]
    I --> J[S3 Output]
    C --> K[Lambda: Finalizer]
    K --> L[SNS]
    K --> M[DynamoDB]
    K --> N[CloudWatch]
```

### 1.2 Integra√ß√£o Lambda ‚Üî Step Functions

**Status**: ‚úÖ BEM IMPLEMENTADO

**An√°lise**:
- [`workflow.asl.json`](infrastructure/statemachine/workflow.asl.json:23): Invoca√ß√£o correta de Lambda via `arn:aws:states:::lambda:invoke`
- [`app.py`](src/functions/transcribe/app.py:45): Parse de evento flex√≠vel suporta m√∫ltiplos formatos
- **Gap Identificado**: Falta valida√ß√£o de schema do evento Step Functions

**Recomenda√ß√£o**:
```python
# Adicionar em src/functions/transcribe/app.py
from jsonschema import validate, ValidationError

STEP_FUNCTIONS_SCHEMA = {
    "type": "object",
    "required": ["execution_id", "video_s3_uri"],
    "properties": {
        "execution_id": {"type": "string"},
        "video_s3_uri": {"type": "string", "pattern": "^s3://"}
    }
}
```

### 1.3 Integra√ß√£o ECS ‚Üî Step Functions

**Status**: ‚ö†Ô∏è REQUER ATEN√á√ÉO

**Problema Identificado**: 
- [`workflow.asl.json`](infrastructure/statemachine/workflow.asl.json:154): ECS Task requer subnet, mas template n√£o define VPC/Subnet
- [`template.yaml`](infrastructure/template.yaml:729): TaskDefinition usa `awsvpc` mas sem VPC configurado

**Impacto**: BLOQUEANTE - workflow n√£o pode executar ECS task

**Solu√ß√£o Requerida**:

**Op√ß√£o A - Usar VPC Padr√£o** (R√°pido):
```yaml
# Em template.yaml
DefaultVPC:
  Type: AWS::EC2::VPC
  Properties:
    CidrBlock: 10.0.0.0/16

PublicSubnet:
  Type: AWS::EC2::Subnet
  Properties:
    VpcId: !Ref DefaultVPC
    CidrBlock: 10.0.1.0/24
    MapPublicIpOnLaunch: true
```

**Op√ß√£o B - Sem VPC** (Mais simples):
```json
// Em workflow.asl.json - usar default VPC account
"NetworkConfiguration": {
  "AwsvpcConfiguration": {
    "Subnets": ["subnet-xxxxx"],  // Subnet p√∫blica da conta
    "AssignPublicIp": "ENABLED"
  }
}
```

### 1.4 Integra√ß√£o Bedrock ‚Üî Processor

**Status**: ‚úÖ EXCELENTE

**Pontos Fortes**:
- [`llm_client.py`](src/processor/llm_client.py:107): Cliente robusto com retry e rate limiting
- [`llm_client.py`](src/processor/llm_client.py:48): RateLimiter implementado corretamente (10 req/min, 100K tokens/min)
- [`llm_client.py`](src/processor/llm_client.py:24): TokenUsage tracking para c√°lculo de custos

---

## üîÑ 2. AN√ÅLISE DE FLUXO DE DADOS E TRANSFORMA√á√ïES

### 2.1 Pipeline de 6 Est√°gios

**Status**: ‚úÖ BEM ARQUITETADO

**Est√°gios Implementados**:

1. **Stage 1 - Limpeza** ([`document_generator.py`](src/processor/document_generator.py:267)):
   - ‚úÖ Formata√ß√£o com timestamps e speakers
   - ‚ö†Ô∏è Sem LLM (poderia usar para remo√ß√£o de ru√≠do)

2. **Stage 2 - Extra√ß√£o T√©cnica** ([`document_generator.py`](src/processor/document_generator.py:313)):
   - ‚úÖ Prompt XML estruturado
   - ‚úÖ 5 categorias: diagnostic, solutions, risks, business_rules, configurations
   - ‚úÖ Output JSON parseado

3. **Stage 3 - Mapeamento** ([`document_generator.py`](src/processor/document_generator.py:391)):
   - ‚úÖ Matriz problema ‚Üí solu√ß√£o
   - ‚úÖ Medidas preventivas e debugging steps

4. **Stage 4 - Estrutura√ß√£o** ([`document_generator.py`](src/processor/document_generator.py:458)):
   - ‚úÖ Outline hier√°rquico
   - ‚úÖ 5 se√ß√µes bem definidas

5. **Stage 5 - Reda√ß√£o** ([`document_generator.py`](src/processor/document_generator.py:536)):
   - ‚úÖ max_tokens=8192 para documento completo
   - ‚úÖ Temperature=0.7 para criatividade controlada

6. **Stage 6 - Output** ([`document_generator.py`](src/processor/document_generator.py:632)):
   - ‚úÖ Markdown + DOCX
   - ‚ö†Ô∏è Convers√£o DOCX b√°sica (sem formata√ß√£o inline)

### 2.2 Chunking Adaptativo

**Status**: ‚úÖ IMPLEMENTA√á√ÉO SOFISTICADA

**An√°lise** ([`transcription_parser.py`](src/processor/transcription_parser.py:270)):
- ‚úÖ Breakpoints naturais: speaker changes, pausas >5s
- ‚úÖ Target 80-100K tokens por chunk
- ‚úÖ Overlap de 10% entre chunks
- ‚úÖ Metadata preservada

**Recomenda√ß√£o de Melhoria**:
```python
# Adicionar valida√ß√£o de chunks muito pequenos
if chunk.tokens < 10000:
    logger.warning(f"Chunk {chunk.chunk_id} muito pequeno: {chunk.tokens} tokens")
    # Merge com chunk anterior ou posterior
```

---

## üõ°Ô∏è 3. AN√ÅLISE DE ERROR HANDLING E RETRY

### 3.1 Step Functions Retry Logic

**Status**: ‚úÖ BEM CONFIGURADO

| Componente | Tentativas | Backoff | Delay Inicial |
|------------|-----------|---------|---------------|
| Lambda Functions | 3 | 2x | 2s |
| AWS Transcribe | 5 | 2x | 5s |
| ECS Task | 2 | 2x | 30s |

**An√°lise**:
- ‚úÖ Backoff exponencial previne thundering herd
- ‚úÖ N√∫mero adequado de tentativas por servi√ßo
- ‚úÖ Catch blocks para todos os estados cr√≠ticos

### 3.2 Lambda Retry Strategy

**Status**: ‚úÖ CONSISTENTE

**Finalizer Function** ([`finalizer.py`](src/functions/finalizer/app.py:330)):
- ‚úÖ Exponential backoff com jitter
- ‚úÖ 3 tentativas para DynamoDB
- ‚úÖ Graceful degradation implementada

**Prioridades Corretas**:
1. **Cr√≠tico**: DynamoDB update (com retry)
2. **Importante**: SNS notification
3. **Opcional**: CloudWatch metrics

### 3.3 Gaps Identificados

**‚ùå Gap 1 - Sem Dead Letter Queue (DLQ)**

Lambdas n√£o t√™m DLQ configurado. Em caso de falhas n√£o recuper√°veis, eventos s√£o perdidos.

**Solu√ß√£o**:
```yaml
# Em template.yaml para cada Lambda
DeadLetterConfig:
  TargetArn: !GetAtt ProcessingDLQ.Arn

ProcessingDLQ:
  Type: AWS::SQS::Queue
  Properties:
    QueueName: !Sub ${AWS::StackName}-dlq
    MessageRetentionPeriod: 1209600  # 14 dias
```

**‚ùå Gap 2 - ECS Task Sem Retry em Bedrock Throttling**

Se Bedrock atingir quota, ECS task falha sem retry inteligente.

**Solu√ß√£o**:
```python
# Em llm_client.py - adicionar backoff mais agressivo para throttling
if "ThrottlingException" in error_name:
    sleep_time = 2 ** attempt * 10  # 10s, 20s, 40s
```

---

## üîê 4. AN√ÅLISE DE SEGURAN√áA E IAM

### 4.1 IAM Permissions

**Status**: ‚ö†Ô∏è REQUER REVIS√ÉO

**An√°lise do Template** ([`template.yaml`](infrastructure/template.yaml:774)):

#### ‚úÖ Pontos Fortes:
- Roles separados por fun√ß√£o (Lambda, ECS Execution, ECS Task)
- Least privilege seguido na maioria dos casos
- Encryption at rest em S3 e DynamoDB

#### ‚ö†Ô∏è Oportunidades de Melhoria:

**1. StateMachineRole muito permissivo** ([`template.yaml`](infrastructure/template.yaml:794)):
```yaml
# Atual - muito aberto
- Effect: Allow
  Action:
    - ecs:RunTask
    - ecs:StopTask
    - ecs:DescribeTasks
  Resource: '*'  # ‚ùå Wildcard

# Recomendado
- Effect: Allow
  Action:
    - ecs:RunTask
    - ecs:StopTask
    - ecs:DescribeTasks
  Resource: 
    - !GetAtt ProcessingTaskDefinition.Arn
    - !Sub 'arn:aws:ecs:${AWS::Region}:${AWS::AccountId}:task/${ProcessingCluster}/*'
```

**2. Bedrock permissions sem restri√ß√£o de modelo**:
```yaml
# Atual
- Effect: Allow
  Action:
    - bedrock:InvokeModel
    - bedrock:InvokeModelWithResponseStream
  Resource: !Sub arn:aws:bedrock:${AWS::Region}::foundation-model/*

# Recomendado - restringir ao modelo usado
Resource: !Sub arn:aws:bedrock:${AWS::Region}::foundation-model/anthropic.claude-sonnet-4*
```

### 4.2 Secrets Management

**Status**: ‚ùå AUSENTE

**Problema**: N√£o h√° gerenciamento de secrets. Se houver necessidade de API keys externas no futuro:

**Solu√ß√£o Recomendada**:
```yaml
ProcessorSecrets:
  Type: AWS::SecretsManager::Secret
  Properties:
    Name: !Sub ${AWS::StackName}-processor-secrets
    SecretString: !Sub |
      {
        "EXTERNAL_API_KEY": "${ExternalApiKey}"
      }
```

### 4.3 Encryption

**Status**: ‚úÖ BOM, mas pode melhorar

- ‚úÖ S3 com SSE-S3
- ‚úÖ DynamoDB encryption enabled
- ‚ö†Ô∏è SNS sem CMK (usando aws/sns default)

**Recomenda√ß√£o para Compliance**:
```yaml
# Usar KMS CMK para SNS
NotificationTopicKey:
  Type: AWS::KMS::Key
  Properties:
    Description: Key for SNS notifications
    KeyPolicy: {...}

NotificationTopic:
  Properties:
    KmsMasterKeyId: !Ref NotificationTopicKey
```

---

## üí∞ 5. AN√ÅLISE DE CUSTOS E OTIMIZA√á√ïES

### 5.1 Custo Estimado Atual

**Por Execu√ß√£o (v√≠deo 3h)**:
- AWS Transcribe: $0.36 (180 min √ó $0.024/min)
- Bedrock Claude 4: $0.90 (~100K in, 20K out)
- ECS Fargate: $0.15 (2 vCPU, 8GB, 45 min)
- S3 + Lambda + outros: $0.04
- **Total**: ~$1.45 ‚úÖ Dentro do estimado

### 5.2 Oportunidades de Otimiza√ß√£o

#### üéØ Otimiza√ß√£o 1 - ECS Fargate Spot

**Economia Potencial**: 50-70% no ECS

```yaml
# Em template.yaml
ProcessingCluster:
  Properties:
    CapacityProviders:
      - FARGATE
      - FARGATE_SPOT  # ‚úÖ J√° configurado
    DefaultCapacityProviderStrategy:
      - CapacityProvider: FARGATE_SPOT
        Weight: 4
      - CapacityProvider: FARGATE
        Weight: 1
```

**Tradeoff**: Pode ter interrup√ß√µes (aceit√°vel para batch processing)

#### üéØ Otimiza√ß√£o 2 - Reduzir Chunking Overhead

**Problema Atual**: Multi-chunk processa stages 1-4 para CADA chunk

**Solu√ß√£o** ([`document_generator.py`](src/processor/document_generator.py:226)):
```python
# Otimiza√ß√£o: processar apenas Stage 1 localmente por chunk
# Stages 2-4 apenas uma vez com dados agregados
def _process_multiple_chunks_optimized(chunks):
    # Stage 1 local para todos chunks (r√°pido)
    cleaned_chunks = [self._stage_1_clean_transcription(c) for c in chunks]
    
    # Merge e processar Stages 2-4 UMA VEZ
    merged_text = "\n\n".join(c.output for c in cleaned_chunks)
    stage_2 = self._stage_2_extract_technical_content(merged_text)
    # ... continuar
```

**Economia**: ~30-40% em chamadas LLM para v√≠deos multi-chunk

#### üéØ Otimiza√ß√£o 3 - CloudWatch Logs Retention

**Atual**: 30 dias para todos logs  
**Recomendado**: 
- Processor logs: 7 dias (s√£o grandes)
- Lambda logs: 30 dias
- Step Functions logs: 30 dias

**Economia**: ~$5-10/m√™s

#### üéØ Otimiza√ß√£o 4 - S3 Intelligent-Tiering

```yaml
TranscriptionBucket:
  Properties:
    LifecycleConfiguration:
      Rules:
        - Id: DeleteOld
          Status: Enabled
          ExpirationInDays: 7
        - Id: IntelligentTier  # ‚úÖ Adicionar
          Status: Enabled
          Transitions:
            - StorageClass: INTELLIGENT_TIERING
              TransitionInDays: 0
```

**Economia**: 40-60% em custos S3 para arquivos antigos

---

## ‚ö†Ô∏è 6. RISCOS ARQUITETURAIS IDENTIFICADOS

### üî¥ Risco Cr√≠tico 1 - Bedrock Quota Limits

**Probabilidade**: ALTA  
**Impacto**: CR√çTICO  
**Status**: ‚ö†Ô∏è N√ÉO MITIGADO

**Problema**:
- Default quota Bedrock: 10 req/min, 200K tokens/min
- Pipeline usa ~5-6 chamadas LLM por v√≠deo
- Com processamento paralelo (2-3 v√≠deos), pode exceder quota

**Mitiga√ß√µes Recomendadas**:

1. **Imediato** - Solicitar aumento de quota
2. **C√≥digo** - Adicionar circuit breaker:
```python
class BedrockCircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=300):
        self.failures = 0
        self.threshold = failure_threshold
        self.timeout = timeout
        self.last_failure = None
        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN
    
    def call(self, func):
        if self.state == 'OPEN':
            if time.time() - self.last_failure > self.timeout:
                self.state = 'HALF_OPEN'
            else:
                raise CircuitBreakerOpen("Bedrock quota exceeded")
        
        try:
            result = func()
            if self.state == 'HALF_OPEN':
                self.state = 'CLOSED'
                self.failures = 0
            return result
        except QuotaException:
            self.failures += 1
            self.last_failure = time.time()
            if self.failures >= self.threshold:
                self.state = 'OPEN'
            raise
```

3. **Monitoramento** - Alarme CloudWatch:
```yaml
BedrockQuotaAlarm:
  Type: AWS::CloudWatch::Alarm
  Properties:
    MetricName: ModelInvocationThrottles
    Namespace: AWS/Bedrock
    Threshold: 5
    EvaluationPeriods: 1
```

### üî¥ Risco Cr√≠tico 2 - ECS Task Memory Overflow

**Probabilidade**: M√âDIA  
**Impacto**: ALTO  
**Status**: ‚ö†Ô∏è MONITORAMENTO INSUFICIENTE

**Problema**:
- V√≠deos 3h ‚Üí transcri√ß√£o ~500KB-1MB
- Pipeline carrega tudo em mem√≥ria
- Multi-chunk pode criar objetos grandes

**An√°lise de Mem√≥ria**:
```
Transcription JSON: ~1MB
Parsed segments: ~2MB
Stage outputs: ~5MB cada √ó 5 stages = 25MB
Markdown final: ~200KB
DOCX generation: ~5MB peak
Total estimado: ~35-40MB por execu√ß√£o
```

**Recomenda√ß√£o**: OK para 8GB, mas adicionar monitoramento:
```python
import psutil

def log_memory_usage():
    process = psutil.Process()
    mem = process.memory_info().rss / 1024 / 1024  # MB
    logger.info(f"Memory usage: {mem:.2f} MB")
    
    if mem > 6000:  # 75% of 8GB
        logger.warning(f"High memory usage: {mem:.2f} MB")
```

### üü° Risco M√©dio 1 - DynamoDB Hot Partition

**Probabilidade**: BAIXA  
**Impacto**: M√âDIO

**Problema**: 
- GSI `video-key-index` pode criar hot partition se muitos v√≠deos processados simultaneamente
- Partition key: `video_key` (n√£o bem distribu√≠do se uploads em batch)

**Solu√ß√£o**: Adicionar shard key:
```python
# Adicionar ao video_key
shard_id = hash(video_key) % 10  # 10 shards
partition_key = f"{video_key}#{shard_id}"
```

### üü° Risco M√©dio 2 - Step Functions Execution History Limits

**Limite**: 25K eventos por execu√ß√£o  
**Risco**: Execu√ß√µes longas com muitos retries podem exceder

**Mitiga√ß√£o**: J√° OK - workflow tem poucos estados (13)

---

## üìä 7. M√âTRICAS E OBSERVABILIDADE

### 7.1 M√©tricas Implementadas

**Status**: ‚úÖ BOM

**CloudWatch Metrics** ([`finalizer.py`](src/functions/finalizer/app.py:627)):
- ‚úÖ ProcessingDuration
- ‚úÖ ProcessingSuccess/Failure/PartialSuccess
- ‚úÖ TokensProcessed
- ‚úÖ DocumentSize
- ‚úÖ ProcessingCost
- ‚úÖ SpeakersDetected

### 7.2 Gaps em Observabilidade

**‚ùå Falta X-Ray Tracing**

Step Functions tem tracing habilitado, mas Lambdas e ECS n√£o instrumentados.

**Solu√ß√£o**:
```python
# Adicionar em cada Lambda e main.py
from aws_xray_sdk.core import xray_recorder
from aws_xray_sdk.core import patch_all

patch_all()

@xray_recorder.capture('process_video')
def lambda_handler(event, context):
    ...
```

**‚ùå Falta Dashboard CloudWatch**

**Solu√ß√£o**: Criar dashboard com:
- Taxa de sucesso vs falha
- Dura√ß√£o m√©dia de processamento
- Custos por execu√ß√£o
- Backlog de processamento

---

## üéØ 8. RECOMENDA√á√ïES PRIORIT√ÅRIAS

### Prioridade P0 (BLOQUEANTE - fazer antes de deploy)

1. **[CR√çTICO] Configurar VPC/Subnet para ECS Task**
   - Workflow n√£o pode executar sem isso
   - Op√ß√£o r√°pida: usar VPC default
   - Arquivo: [`workflow.asl.json`](infrastructure/statemachine/workflow.asl.json:160)

2. **[CR√çTICO] Solicitar aumento de quota Bedrock**
   - Limite atual pode bloquear processamento
   - Solicitar: 50 req/min, 500K tokens/min

### Prioridade P1 (IMPORTANTE - fazer logo ap√≥s deploy)

3. **Adicionar Dead Letter Queue para Lambdas**
   - Prevenir perda de eventos
   - Arquivo: [`template.yaml`](infrastructure/template.yaml:1)

4. **Implementar Circuit Breaker para Bedrock**
   - Prote√ß√£o contra quota exhaustion
   - Arquivo: [`llm_client.py`](src/processor/llm_client.py:107)

5. **Restringir IAM permissions (StateMachineRole)**
   - Seguir least privilege
   - Arquivo: [`template.yaml`](infrastructure/template.yaml:794)

6. **Adicionar X-Ray tracing completo**
   - Melhorar observabilidade
   - Arquivos: todas Lambdas e [`main.py`](src/processor/main.py:1)

### Prioridade P2 (MELHORIAS - roadmap)

7. **Otimizar processamento multi-chunk**
   - Reduzir chamadas LLM desnecess√°rias
   - Arquivo: [`document_generator.py`](src/processor/document_generator.py:226)

8. **Implementar CloudWatch Dashboard**
   - Visibilidade operacional

9. **Configurar ECS Fargate Spot**
   - Economia de 50-70% em custos
   - Arquivo: [`template.yaml`](infrastructure/template.yaml:718)

10. **Melhorar convers√£o Markdown‚ÜíDOCX**
    - Suporte a formata√ß√£o inline
    - Arquivo: [`document_generator.py`](src/processor/document_generator.py:685)

---

## üìà 9. AVALIA√á√ÉO DE QUALIDADE

### Code Quality Score: 8.5/10

| Aspecto | Score | Coment√°rio |
|---------|-------|------------|
| Arquitetura | 9/10 | Bem pensada, serverless first |
| Implementa√ß√£o | 9/10 | C√≥digo limpo, bem estruturado |
| Error Handling | 8/10 | Robusto, mas falta DLQ |
| Seguran√ßa | 7/10 | Boa base, needs IAM tightening |
| Observabilidade | 7/10 | M√©tricas OK, falta X-Ray |
| Documenta√ß√£o | 9/10 | Excelente README e design docs |
| Testes | 8/10 | Unit tests bons, falta integration |
| Performance | 8/10 | Adequado, com room for optimization |

### Architecture Maturity: N√≠vel 3 (de 5)

- ‚úÖ **N√≠vel 1**: Funcional b√°sico
- ‚úÖ **N√≠vel 2**: Error handling e retry
- ‚úÖ **N√≠vel 3**: Observabilidade e m√©tricas
- ‚è≥ **N√≠vel 4**: Auto-scaling e chaos engineering
- ‚è≥ **N√≠vel 5**: Multi-region e disaster recovery

---

## üîÑ 10. PR√ìXIMOS PASSOS RECOMENDADOS

### Imediato (Antes de primeiro deploy)
1. ‚úÖ Resolver issue VPC/Subnet (P0)
2. ‚úÖ Solicitar quota Bedrock (P0)
3. ‚úÖ Validar template SAM completo
4. ‚úÖ Criar checklist de pre-flight

### Curto Prazo (Primeira semana de produ√ß√£o)
1. Adicionar DLQ (P1)
2. Implementar Circuit Breaker (P1)
3. Deploy dashboard de monitoramento
4. Setup alarmes cr√≠ticos
5. Monitorar custos reais vs estimados

### M√©dio Prazo (Primeiro m√™s)
1. Otimiza√ß√µes de custo (Fargate Spot, etc.)
2. Melhorar observabilidade (X-Ray)
3. Testes de carga
4. Documenta√ß√£o operacional (runbooks)

---

## üìù CONCLUS√ÉO

O projeto AI Techne Academy demonstra **excelente qualidade t√©cnica** e est√° **85% pronto para produ√ß√£o**. A arquitetura √© s√≥lida, o c√≥digo √© limpo e bem estruturado, e a documenta√ß√£o √© exemplar.

**Principais Conquistas**:
- ‚úÖ Arquitetura serverless bem planejada
- ‚úÖ Pipeline de 6 est√°gios sofisticado
- ‚úÖ Error handling robusto com retry logic
- ‚úÖ Chunking adaptativo inteligente
- ‚úÖ Tracking completo de custos e tokens

**Bloqueios Cr√≠ticos**:
- ‚ùå VPC/Subnet n√£o configurado para ECS
- ‚ö†Ô∏è Bedrock quota limits n√£o mitigados

**Recomenda√ß√£o Final**: 
Resolver os 2 bloqueios P0, implementar as 4 melhorias P1, e o sistema estar√° **pronto para produ√ß√£o** com alta confian√ßa.

---

**Revisado por**: Kilo (Architect Mode)  
**Data**: 2024-12-11  
**Pr√≥xima Revis√£o**: Ap√≥s deploy inicial