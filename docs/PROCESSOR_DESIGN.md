# Processador ECS - Design T√©cnico Detalhado

**Vers√£o**: 1.0.0  
**Data**: 2024-12-11  
**Status**: Em Desenvolvimento  
**Componente**: ECS Fargate Task - Processamento Principal

---

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura](#arquitetura)
3. [Pipeline de 6 Etapas](#pipeline-de-6-etapas)
4. [Componentes Detalhados](#componentes-detalhados)
5. [Integra√ß√£o AWS Bedrock](#integra√ß√£o-aws-bedrock)
6. [Chunking Adaptativo](#chunking-adaptativo)
7. [Gera√ß√£o de Documentos](#gera√ß√£o-de-documentos)
8. [Estrutura de Inputs/Outputs](#estrutura-de-inputsoutputs)
9. [Error Handling](#error-handling)
10. [Testes](#testes)
11. [Implementa√ß√£o](#implementa√ß√£o)

---

## Vis√£o Geral

### Objetivo

O Processador ECS √© o **componente central** do sistema AI Techne Academy. Ele recebe transcri√ß√µes do AWS Transcribe, processa o conte√∫do usando AWS Bedrock (Claude Sonnet 4), e gera documentos de treinamento t√©cnico em formatos Markdown e DOCX.

### Responsabilidades

1. **Parse de Transcri√ß√µes**: Ler e processar JSON do AWS Transcribe
2. **Chunking Inteligente**: Dividir transcri√ß√µes longas (>200K tokens)
3. **Processamento LLM**: Invocar Claude Sonnet 4 via AWS Bedrock usando LangChain
4. **Pipeline de 6 Etapas**: Executar workflow de gera√ß√£o de documentos
5. **Gera√ß√£o de Outputs**: Criar documentos Markdown e DOCX
6. **Upload S3**: Salvar documentos no bucket de output
7. **Tracking**: Atualizar DynamoDB com progresso e resultados

### Tecnologias

- **Runtime**: Python 3.12
- **Container**: Docker (Alpine-based)
- **Orquestra√ß√£o**: ECS Fargate (2 vCPU, 8GB RAM)
- **LLM Client**: LangChain + AWS Bedrock
- **Formato Sa√≠da**: Markdown + DOCX (python-docx)
- **AWS Services**: S3, Bedrock, DynamoDB, CloudWatch

---

## Arquitetura

### Diagrama de Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ECS Fargate Task                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                   main.py                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (Entry Point & Orchestration)                          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ              ‚îÇ                                               ‚îÇ
‚îÇ              ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ              ‚îÇ              ‚îÇ              ‚îÇ            ‚îÇ   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ transcription_ ‚îÇ ‚îÇ llm_client  ‚îÇ ‚îÇdocument_‚îÇ ‚îÇ utils ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   parser.py    ‚îÇ ‚îÇ   .py       ‚îÇ ‚îÇgenerator‚îÇ ‚îÇ  .py  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Dependencies:                                               ‚îÇ
‚îÇ  ‚Ä¢ boto3 (S3, DynamoDB)                                      ‚îÇ
‚îÇ  ‚Ä¢ langchain-aws (BedrockChat)                               ‚îÇ
‚îÇ  ‚Ä¢ python-docx (DOCX generation)                             ‚îÇ
‚îÇ  ‚Ä¢ tiktoken (token counting)                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                    ‚îÇ                    ‚îÇ
         ‚îÇ Read               ‚îÇ Invoke             ‚îÇ Write
         ‚ñº                    ‚ñº                    ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   S3   ‚îÇ          ‚îÇ Bedrock  ‚îÇ         ‚îÇ   S3   ‚îÇ
    ‚îÇ(Input) ‚îÇ          ‚îÇ(Claude)  ‚îÇ         ‚îÇ(Output)‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                                        ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ DynamoDB ‚îÇ
                  ‚îÇ(Tracking)‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Fluxo de Execu√ß√£o

```mermaid
graph TD
    A[ECS Task Iniciado] --> B[main.py: Parse Input]
    B --> C[Carregar Transcri√ß√£o do S3]
    C --> D[transcription_parser: Parse JSON]
    D --> E{Transcri√ß√£o > 200K tokens?}
    E -->|Sim| F[Chunking Adaptativo]
    E -->|N√£o| G[Processar Completo]
    F --> H[Pipeline 6 Etapas]
    G --> H
    H --> I[Etapa 1: Limpeza]
    I --> J[Etapa 2: Extra√ß√£o T√©cnica]
    J --> K[Etapa 3: Mapeamento Solu√ß√µes]
    K --> L[Etapa 4: Estrutura√ß√£o]
    L --> M[Etapa 5: Reda√ß√£o]
    M --> N[Etapa 6: Gera√ß√£o Outputs]
    N --> O[Salvar Markdown no S3]
    O --> P[Converter para DOCX]
    P --> Q[Salvar DOCX no S3]
    Q --> R[Atualizar DynamoDB]
    R --> S[Task Conclu√≠do]
```

---

## Pipeline de 6 Etapas

### Etapa 1: An√°lise e Limpeza da Transcri√ß√£o

**Objetivo**: Preparar a transcri√ß√£o para processamento.

**Opera√ß√µes**:
- Parse do JSON do AWS Transcribe
- Extra√ß√£o de texto e timestamps
- Identifica√ß√£o de speakers (spk_0, spk_1, etc.)
- Remo√ß√£o de ru√≠do:
  - Cumprimentos e sauda√ß√µes gen√©ricas
  - Pausas para caf√©/banheiro
  - Problemas t√©cnicos (√°udio, conex√£o)
  - Conversas n√£o t√©cnicas
- Segmenta√ß√£o por t√≥picos/timestamps

**Input**: JSON do Transcribe
**Output**: Texto limpo com speakers e timestamps

**Implementa√ß√£o**: `transcription_parser.py`

---

### Etapa 2: Extra√ß√£o de Conte√∫do T√©cnico

**Objetivo**: Identificar e extrair todos os elementos t√©cnicos relevantes.

**Prompt Base**:

```xml
<task>
Voc√™ √© um Especialista em Documenta√ß√£o T√©cnica de Software. Analise a transcri√ß√£o fornecida e extraia conte√∫do t√©cnico.
</task>

<instructions>
Ignore di√°logos sociais. Concentre-se exclusivamente no conte√∫do t√©cnico e extraia:

1. <diagnostic>
   Liste erros espec√≠ficos (c√≥digos, mensagens, exce√ß√µes).
   Para cada erro, identifique a causa raiz explicada.
</diagnostic>

2. <solutions>
   Descreva passos t√©cnicos executados.
   Inclua comandos, altera√ß√µes de c√≥digo, configura√ß√µes.
</solutions>

3. <risks>
   Identifique avisos sobre ambientes compartilhados, concorr√™ncia, 
   procedimentos que afetam outros membros da equipe.
</risks>

4. <business_rules>
   Extraia explica√ß√µes sobre comportamento do sistema.
   Por que dados aparecem com valor X ou Y?
</business_rules>

5. <configurations>
   Liste conven√ß√µes de nomenclatura (prefixos, sufixos).
   Configura√ß√µes espec√≠ficas de ferramentas.
</configurations>
</instructions>

<output_format>
Gere um JSON estruturado contendo os 5 elementos acima.
Use listas para m√∫ltiplos itens em cada categoria.
</output_format>

<transcription>
{TRANSCRIPTION_TEXT}
</transcription>
```

**Input**: Texto limpo da Etapa 1  
**Output**: JSON estruturado com 5 categorias t√©cnicas

---

### Etapa 3: Mapeamento de Solu√ß√µes

**Objetivo**: Criar rela√ß√£o clara entre problemas e solu√ß√µes.

**Prompt Base**:

```xml
<task>
Voc√™ √© um Engenheiro de Software S√™nior. Crie um mapeamento entre problemas e solu√ß√µes.
</task>

<instructions>
Com base no conte√∫do t√©cnico extra√≠do, crie uma matriz problema-solu√ß√£o:

1. <problem_solution_map>
   Para cada erro/problema identificado:
   - C√≥digo/mensagem do erro
   - Causa raiz
   - Solu√ß√£o aplicada (passo a passo)
   - Comandos executados
   - Resultado obtido
</problem_solution_map>

2. <preventive_measures>
   Liste medidas preventivas mencionadas.
   Como evitar o problema no futuro?
</preventive_measures>

3. <debugging_steps>
   Passos de debug/investiga√ß√£o mencionados.
   Como diagnosticar o problema?
</debugging_steps>
</instructions>

<output_format>
Gere um JSON estruturado com os 3 elementos acima.
Organize de forma hier√°rquica (problema ‚Üí causa ‚Üí solu√ß√£o).
</output_format>

<technical_content>
{EXTRACTED_CONTENT_FROM_STAGE_2}
</technical_content>
```

**Input**: JSON da Etapa 2  
**Output**: JSON com mapeamento problema-solu√ß√£o

---

### Etapa 4: Estrutura√ß√£o do Documento

**Objetivo**: Criar a estrutura l√≥gica do documento final.

**Prompt Base**:

```xml
<task>
Voc√™ √© um Designer Instrucional T√©cnico. Crie a estrutura para um Guia de Treinamento e Troubleshooting.
</task>

<instructions>
Organize os t√≥picos da seguinte forma:

1. <troubleshooting_section>
   - Compara√ß√£o entre tipos de erros (Compila√ß√£o vs Runtime vs Configura√ß√£o)
   - Cada erro associado √† sua solu√ß√£o imediata
   - Sintomas e diagn√≥stico
</troubleshooting_section>

2. <practical_procedure>
   - Passo a passo da solu√ß√£o t√©cnica
   - Se√ß√£o espec√≠fica: 'Instrumenta√ß√£o e Debug'
   - Como rastrear o problema
   - Comandos e ferramentas utilizadas
</practical_procedure>

3. <safety_protocols>
   - Cuidados com ambiente compartilhado
   - Como n√£o impactar colegas
   - Se√ß√£o destacada como CR√çTICA
</safety_protocols>

4. <business_understanding>
   - Interpreta√ß√£o dos resultados
   - Explica√ß√£o de regras de neg√≥cio
   - Por que o sistema se comporta assim?
</business_understanding>

5. <faq_section>
   - D√∫vidas comuns encontradas
   - Respostas objetivas
</faq_section>
</instructions>

<output_format>
Gere apenas a estrutura (outline) em formato hier√°rquico.
Use bullet points detalhando o que ser√° abordado em cada se√ß√£o.
N√ÉO escreva o conte√∫do completo ainda.
</output_format>

<mapped_solutions>
{SOLUTION_MAP_FROM_STAGE_3}
</mapped_solutions>
```

**Input**: JSON da Etapa 3  
**Output**: Outline estruturado

---

### Etapa 5: Reda√ß√£o do Conte√∫do

**Objetivo**: Escrever o documento completo em Markdown.

**Prompt Base**:

```xml
<task>
Atue como um Redator T√©cnico S√™nior. Escreva um Documento de Treinamento e Troubleshooting completo em Markdown.
</task>

<guidelines>
- Tom: Profissional, instrucional, direto (imperativo: 'Fa√ßa', 'Configure', 'Verifique')
- Clareza: Acess√≠vel para iniciantes. Explique o 'porqu√™', n√£o apenas o 'como'
- Formata√ß√£o: Use code blocks, negrito para √™nfase, blockquotes para avisos cr√≠ticos
</guidelines>

<required_structure>
# 1. Introdu√ß√£o
- Contexto: por que este documento existe?
- Qual problema/tema est√° sendo abordado?
- Objetivo final para o leitor

# 2. Desenvolvimento
## 2.1 Conceitos-chave
## 2.2 Troubleshooting Guide
## 2.3 Procedimento Passo a Passo
## 2.4 Melhores Pr√°ticas
## 2.5 Considera√ß√µes de Seguran√ßa
## 2.6 Entendendo os Dados (Regras de Neg√≥cio)

# 3. Encerramento
- Resumo do que foi aprendido
- Refor√ßo da mensagem principal
- Pr√≥ximos passos/a√ß√µes

# 4. FAQ
- D√∫vidas comuns
- Respostas objetivas e claras
</required_structure>

<document_outline>
{OUTLINE_FROM_STAGE_4}
</document_outline>
```

**Input**: Outline da Etapa 4  
**Output**: Documento Markdown completo

---

### Etapa 6: Gera√ß√£o de Outputs

**Objetivo**: Salvar documentos em m√∫ltiplos formatos.

**Opera√ß√µes**:

1. **Salvar Markdown**: `s3://{output_bucket}/{execution_id}/document.md`
2. **Converter para DOCX**: Usando `python-docx`
3. **Salvar DOCX**: `s3://{output_bucket}/{execution_id}/document.docx`
4. **Valida√ß√£o**: Tamanho m√≠nimo, estrutura v√°lida

**Input**: Markdown da Etapa 5  
**Output**: Arquivos `.md` e `.docx` no S3

---

## Componentes Detalhados

### 1. transcription_parser.py

```python
class TranscriptionParser:
    """Parser para transcri√ß√µes do AWS Transcribe."""
    
    def __init__(self, s3_client):
        self.s3_client = s3_client
        
    def parse_transcribe_json(self, json_data: dict) -> dict:
        """Parse do JSON do AWS Transcribe."""
        
    def chunk_transcription(self, text: str, max_tokens: int = 100000) -> list:
        """Divide transcri√ß√£o em chunks inteligentes."""
        
    def count_tokens(self, text: str) -> int:
        """Conta tokens usando tiktoken."""
```

### 2. llm_client.py

```python
from langchain_aws import ChatBedrock

class BedrockLLMClient:
    """Cliente LangChain para AWS Bedrock."""
    
    def __init__(self, model_id: str = "anthropic.claude-sonnet-4-5-20250929-v1:0"):
        self.model = ChatBedrock(
            model_id=model_id,
            region_name="us-east-1",
            model_kwargs={"temperature": 0.7, "max_tokens": 4096}
        )
        
    def invoke(self, prompt: str) -> str:
        """Invoca o modelo com retry logic."""
```

### 3. document_generator.py

```python
class DocumentGenerator:
    """Gerador de documentos usando pipeline de 6 etapas."""
    
    def __init__(self, llm_client, parser, s3_client):
        self.llm = llm_client
        self.parser = parser
        self.s3 = s3_client
        
    def generate_document(self, execution_id: str, 
                         transcription_uri: str,
                         output_bucket: str) -> dict:
        """Executa pipeline completo de 6 etapas."""
```

### 4. main.py

```python
def lambda_handler(event: dict, context) -> dict:
    """Handler principal do processador ECS."""
    
    # Setup
    execution_id = event['execution_id']
    
    # Initialize
    parser = TranscriptionParser(s3_client)
    llm = BedrockLLMClient()
    generator = DocumentGenerator(llm, parser, s3_client)
    
    # Generate
    result = generator.generate_document(execution_id, ...)
    
    return {'statusCode': 200, 'body': result}
```

---

## Integra√ß√£o AWS Bedrock

### Configura√ß√£o

```python
from langchain_aws import ChatBedrock

chat = ChatBedrock(
    model_id="anthropic.claude-sonnet-4-5-20250929-v1:0",
    region_name="us-east-1",
    model_kwargs={
        "temperature": 0.7,
        "max_tokens": 4096,
        "top_p": 0.95
    }
)
```

### Custos

```python
INPUT_PRICE_PER_1K = 0.003   # $0.003 per 1K tokens
OUTPUT_PRICE_PER_1K = 0.015  # $0.015 per 1K tokens
```

---

## Chunking Adaptativo

### Estrat√©gia

1. Contar tokens totais
2. Se ‚â§ 100K tokens: processar completo
3. Se > 100K tokens:
   - Identificar breakpoints naturais (mudan√ßas de speaker, pausas)
   - Criar chunks de ~80-100K tokens
   - Overlap de 10K tokens entre chunks
   - Adicionar metadata

### Implementa√ß√£o

```python
def adaptive_chunking(text: str, max_tokens: int = 100000) -> list:
    """Chunking adaptativo baseado em conte√∫do."""
    
    total_tokens = count_tokens(text)
    
    if total_tokens <= max_tokens:
        return [{'chunk_id': 0, 'text': text}]
    
    # Multi-chunk logic
    num_chunks = math.ceil(total_tokens / max_tokens)
    return create_chunks_with_overlap(text, num_chunks)
```

---

## Gera√ß√£o de Documentos

### Markdown ‚Üí DOCX

```python
from docx import Document

class MarkdownToDocxConverter:
    """Converte Markdown para DOCX."""
    
    def convert(self, markdown_text: str) -> Document:
        """
        Suporte para:
        - Headers (# ## ###)
        - Bold (**text**), Italic (*text*)
        - Code blocks (```)
        - Lists (bullet e numeradas)
        - Blockquotes (>)
        - Tables
        """
        doc = Document()
        # Processar linha por linha
        return doc
```

---

## Estrutura de Inputs/Outputs

### Event Input (Step Functions)

```json
{
  "execution_id": "uuid-1234",
  "video_s3_uri": "s3://input-bucket/video.mp4",
  "transcription_s3_uri": "s3://transcripts-bucket/uuid/transcription.json",
  "output_bucket": "output-bucket",
  "tracking_table": "tracking-table-name"
}
```

### Response Output

```json
{
  "statusCode": 200,
  "body": {
    "markdown_s3_uri": "s3://output/uuid/document.md",
    "docx_s3_uri": "s3://output/uuid/document.docx",
    "tokens_used": {
      "input": 150000,
      "output": 8000
    },
    "cost_usd": 0.57,
    "duration_seconds": 185
  }
}
```

---

## Error Handling

### Estrat√©gia

```python
try:
    result = generator.generate_document(...)
except BedrockThrottlingException:
    # Retry com backoff
    retry_with_backoff()
except BedrockValidationException:
    # Erro permanente - n√£o retry
    raise
except Exception as e:
    # Log e notificar
    logger.error(f"Unexpected error: {e}")
    update_tracking_failed()
    raise
```

---

## Testes

### Casos de Teste

1. **Transcri√ß√£o curta (<100K tokens)**: Processamento direto
2. **Transcri√ß√£o longa (>200K tokens)**: Chunking e merge
3. **M√∫ltiplos speakers**: Identifica√ß√£o correta
4. **Errors handling**: Retry e fallback
5. **Formato outputs**: Markdown e DOCX v√°lidos

---

## Implementa√ß√£o

### Checklist

- [ ] Implementar `transcription_parser.py`
- [ ] Implementar `llm_client.py`
- [ ] Implementar `document_generator.py`
- [ ] Implementar `main.py`
- [ ] Criar testes unit√°rios (>80% cobertura)
- [ ] Documentar README.md
- [ ] Criar Dockerfile
- [ ] Deploy teste ECS

---

**√öltima Atualiza√ß√£o**: 2024-12-11  
**Autor**: Kilo Code (Architect Mode)  
**Status**: Design Completo - Pronto para Implementa√ß√£o