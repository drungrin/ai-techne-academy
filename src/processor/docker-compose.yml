# AI Techne Academy - Processor Development Environment
# Docker Compose configuration for local development and testing

version: '3.8'

services:
  processor:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-techne-processor-dev
    image: ai-techne-processor:dev
    
    # Environment variables
    environment:
      # AWS Configuration
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
      
      # Application Configuration
      - TRACKING_TABLE=${TRACKING_TABLE:-ai-techne-academy-tracking-dev}
      - OUTPUT_BUCKET=${OUTPUT_BUCKET:-ai-techne-academy-output-dev-615934053793}
      - BEDROCK_MODEL_ID=${BEDROCK_MODEL_ID:-anthropic.claude-sonnet-4-5-20250929-v1:0}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - MAX_TOKENS_PER_CHUNK=${MAX_TOKENS_PER_CHUNK:-100000}
      - ENVIRONMENT=${ENVIRONMENT:-dev}
      
      # Python Configuration
      - PYTHONUNBUFFERED=1
    
    # Mount AWS credentials (read-only)
    volumes:
      - ~/.aws:/root/.aws:ro
      # Mount source code for hot reload during development
      - ./:/app
    
    # Keep container running for interactive testing
    # Override this in production with actual command
    command: tail -f /dev/null
    
    # Restart policy
    restart: unless-stopped
    
    # Resource limits (optional, for testing ECS resource constraints)
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 4G
    
    # Network configuration
    networks:
      - ai-techne-network
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  ai-techne-network:
    driver: bridge
    name: ai-techne-network